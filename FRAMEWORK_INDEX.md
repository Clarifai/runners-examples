# Examples by Framework

This index organizes all examples by the framework they use. Use this to find examples for your preferred deployment framework.

## Custom Implementation

- [hello-world](hello-world/) - N/A, N/A GPU, basic-inference
- [nsfw-image-classifier](image-classifier/nsfw-image-classifier/) - N/A, 8Gi GPU, image-classification, nsfw-detection
- [dfine](image-detector/dfine/) - N/A, 8Gi GPU, object-detection
- [stable-diffusion-2-depth](image-text-to-image/stable-diffusion-2-depth/) - N/A, 20Gi GPU, image-to-image, depth-aware, +1 more
- [nanonets-ocr-s](multimodal-models/ocr/nanonets-ocr-s/) - N/A, 20Gi GPU, ocr
- [flux-schnell](text-to-image/flux-schnell/) - N/A, 20Gi GPU, text-to-image, diffusion

## FastMCP

- [browser-mcp-server](mcp-servers/browser-mcp-server/) - N/A, N/A GPU, mcp, browser, +1 more
- [browser-tools](mcp-servers/browser-tools/) - N/A, N/A GPU, mcp, browser, +1 more
- [code-execution-docker-version](mcp-servers/code-execution-docker-version/) - N/A, N/A GPU, mcp, code-execution, +2 more
- [code-execution-without-docker-version](mcp-servers/code-execution-without-docker-version/) - N/A, N/A GPU, mcp, code-execution
- [firecrawl-browser-tools](mcp-servers/firecrawl-browser-tools/) - N/A, N/A GPU, mcp, browser, +1 more
- [github-mcp-server](mcp-servers/github-mcp-server/) - N/A, N/A GPU, mcp, github, +1 more
- [google-drive](mcp-servers/google-drive/) - N/A, N/A GPU, mcp, google-drive, +1 more
- [math](mcp-servers/math/) - N/A, N/A GPU, mcp, calculator
- [postgres](mcp-servers/postgres/) - N/A, N/A GPU, mcp, database, +1 more
- [slack-tools-server](mcp-servers/slack-tools-server/) - N/A, N/A GPU, mcp, slack, +1 more
- [web-search](mcp-servers/web-search/) - N/A, N/A GPU, mcp, search

## LMDeploy

- [lmdeploy-llama-3_2-3b-instruct](llm/lmdeploy-llama-3_2-3b-instruct/) - 3B, 20Gi GPU, text-generation, chat, +1 more

## Ollama

- [ollama-model-upload](local-runners/ollama-model-upload/) - N/A, N/A GPU, local-development

## SGLang

- [sglang-smollm2-135m-instruct](llm/sglang-smollm2-135m-instruct/) - 135M, 8Gi GPU, text-generation, chat, +1 more
- [deepseek-ocr-sglang](multimodal-models/ocr/deepseek-ocr-sglang/) - N/A, 20Gi GPU, ocr, vision-language

## HuggingFace Transformers

- [detr-resnet-image-detection](image-detector/detr-resnet-image-detection/) - N/A, 8Gi GPU, object-detection
- [mask2former-ade](image-segmenter/mask2former-ade/) - N/A, 8Gi GPU, image-segmentation
- [hf-llama-3_2-1b-instruct](llm/hf-llama-3_2-1b-instruct/) - 1B, 8Gi GPU, text-generation, chat
- [jina-embeddings-v3](text-embedder/jina-embeddings-v3/) - N/A, 8Gi GPU, embeddings

## vLLM

- [agentic-gpt-5_1](llm/agentic-gpt-5_1/) - N/A, 48Gi GPU, agentic, tool-calling, +1 more
- [agentic-gpt-oss-20b](llm/agentic-gpt-oss-20b/) - 20B, 48Gi GPU, agentic, tool-calling, +1 more
- [vllm-gemma-3-1b-it](llm/vllm-gemma-3-1b-it/) - 1B, 8Gi GPU, text-generation, chat, +1 more
- [vllm-gemma-3-4b-it](llm/vllm-gemma-3-4b-it/) - 4B, 48Gi GPU, text-generation, chat, +1 more
- [vllm-phi-3.5-mini-instruct](llm/vllm-phi-3.5-mini-instruct/) - 3.8B, 20Gi GPU, text-generation, chat, +1 more
- [vllm-tool-calling-llama-3.1-8b](llm/vllm-tool-calling-llama-3.1-8b/) - 8B, 20Gi GPU, text-generation, tool-calling, +1 more
- [qwen2_5-vl-3b-instruct-vllm](multimodal-models/vision-language/qwen2_5-vl-3b-instruct-vllm/) - 3B, 20Gi GPU, vision-language, chat, +1 more
