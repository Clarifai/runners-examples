# JinaAI Embeddings v3 on Clarifai

## Overview

**JinaAI Embeddings v3** is a high-performance text embedding model deployed on the **Clarifai platform** using a vLLM-backed, OpenAI-compatible runner.  
Once deployed, the model can be accessed using either:

-   **OpenAI-compatible APIs**
    
-   **Clarifai Python SDK**
    

This deployment pattern is **generic** and can be reused to upload and deploy **any embedding model** on Clarifai with minimal changes.

----------

## Common Use Cases

Text embeddings generated by this model can be used for:

-   **Semantic Search**
    
-   **Text Similarity & Clustering**
    
-   **Retrieval-Augmented Generation (RAG)**
    
-   **Document & Knowledge Base Indexing**
    
-   **Text Classification & Topic Modeling**
    
-   **Question Answering Systems**
    

----------

## Model Reference

Use the following model URL format after deployment:

```
https://clarifai.com/<user_id>/<app_id>/models/jinaai-embeddings-v3

```

Replace:

-   `<user_id>` → your Clarifai username
    
-   `<app_id>` → your Clarifai application name
    

----------

## Inference Options

You can run inference using **either** of the following methods.

----------

## 1. Using OpenAI-Compatible API

Clarifai exposes the model through an OpenAI-compatible `/v1/embeddings` endpoint.

### Example

```python
from openai import OpenAI

client = OpenAI(
    base_url="https://api.clarifai.com/v2/ext/openai/v1",
    api_key="YOUR_CLARIFAI_PAT",
)

sentences = [
    "Artificial Intelligence will transform industries.",
    "AI is going to change the world in the future.",
    "I love playing Soccer with my friends.",
    "Soccer is my favorite sport to watch and play.",
]

response = client.embeddings.create(
    model="https://clarifai.com/<user_id>/<app_id>/models/jinaai-embeddings-v3",
    input=sentences,
)

embeddings = [response.data[i].embedding for i in range(len(sentences))]
print(len(embeddings))

```

### When to Use This

-   You already use **OpenAI SDKs**
    
-   You want **drop-in compatibility**
    
-   You are migrating from OpenAI to Clarifai without changing client logic
    

----------

## 2. Using Clarifai Python SDK

Clarifai’s native SDK provides a clean and simple interface.

### Example

```python
from clarifai.client import Model

model = Model(
    url="https://clarifai.com/<user_id>/<app_id>/models/jinaai-embeddings-v3",
    pat="YOUR_CLARIFAI_PAT",
)

texts = [
    "What's the future of AI?",
    "How is AI going to change the world?",
]

embeddings = model.predict(texts=texts)
print(len(embeddings))

```

## Output Format

-   Each input text produces a **fixed-length vector embedding**
    
-   Output type: `List[List[float]]`
    
-   Suitable for similarity search, indexing, and clustering pipelines
    

----------

## Reusing This Deployment Pattern

This runner and deployment approach can be reused for:

-   Any **Hugging Face embedding model**
    
-   Any **vLLM-compatible architecture**
    
-   Any model that supports **OpenAI-style embeddings**
    

### What Typically Changes

-   Model checkpoint (Hugging Face repo)
    
-   Model name & metadata
    
-   Optional vLLM runtime parameters
    

Everything else remains the same.